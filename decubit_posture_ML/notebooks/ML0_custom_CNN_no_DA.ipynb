{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Reading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/training_data.npz', allow_pickle=True)\n",
    "\n",
    "train_set = data['train_set']\n",
    "test_set = data['test_set']\n",
    "val_set = data['val_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(set):\n",
    "    df_ = pd.DataFrame([], columns=['x', 'y'])\t\n",
    "    for i in range(len(set)):\n",
    "        df_ = pd.concat([df_, pd.DataFrame(\n",
    "            {'reading': [set[i]['x']],\n",
    "            'posture': set[i]['y']}\n",
    "        )])\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 4) (54, 4) (27, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train = create_dataframe(train_set)\n",
    "df_test = create_dataframe(test_set)\n",
    "df_val = create_dataframe(val_set)\n",
    "\n",
    "print(df_train.shape, df_test.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['reading'].iat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['reading']\n",
    "y_train = df_train['posture']\n",
    "X_val = df_val['reading']\n",
    "y_val = df_val['posture']\n",
    "X_test = df_test['reading']\n",
    "y_test = df_test['posture']\n",
    "# One-hot encode the labels\n",
    "y_train = pd.get_dummies(y_train).values\n",
    "y_val = pd.get_dummies(y_val).values\n",
    "y_test = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(x) for x in X_train])\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_val = np.array([np.array(x) for x in X_val])\n",
    "X_val = np.expand_dims(X_val, -1)\n",
    "X_test = np.array([np.array(x) for x in X_test])\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = np.array([np.array(x) for x in y_train])\n",
    "y_test = np.array([np.array(x) for x in y_test])\n",
    "y_val = np.array([np.array(x) for x in y_val])\n",
    "# Convert the data to tensors\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Definition\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_channels_1 = hp.Int('channels_1', min_value=4, max_value=16, step=4)\n",
    "    hp_channels_2 = hp.Int('channels_2', min_value=4, max_value=8, step=4)\n",
    "    hp_dense_1 = hp.Int('dense_1', min_value=16, max_value=64, step=16)\n",
    "    hp_dense_2 = hp.Int('dense_2', min_value=16, max_value=32, step=16)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Conv2D(hp_channels_1, kernel_size=(3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(hp_channels_2, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),  # Flatten the output of the CNN\n",
    "            layers.Dense(hp_dense_1, activation='relu'),\n",
    "            layers.Dense(hp_dense_2, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.GridSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_retries_per_trial=5,\n",
    "    overwrite=True,\n",
    "    directory='gridsearch-laguardia-no-DA',\n",
    "    project_name='posture',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 Complete [00h 00m 08s]\n",
      "val_loss: 0.3071151077747345\n",
      "\n",
      "Best val_loss So Far: 0.037137117236852646\n",
      "Total elapsed time: 00h 04m 37s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in gridsearch-laguardia-no-DA/posture\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0015 summary\n",
      "Hyperparameters:\n",
      "channels_1: 4\n",
      "channels_2: 8\n",
      "dense_1: 64\n",
      "dense_2: 32\n",
      "Score: 0.037137117236852646\n",
      "\n",
      "Trial 0041 summary\n",
      "Hyperparameters:\n",
      "channels_1: 12\n",
      "channels_2: 8\n",
      "dense_1: 16\n",
      "dense_2: 32\n",
      "Score: 0.13073788583278656\n",
      "\n",
      "Trial 0031 summary\n",
      "Hyperparameters:\n",
      "channels_1: 8\n",
      "channels_2: 8\n",
      "dense_1: 64\n",
      "dense_2: 32\n",
      "Score: 0.15593186020851135\n",
      "\n",
      "Trial 0055 summary\n",
      "Hyperparameters:\n",
      "channels_1: 16\n",
      "channels_2: 4\n",
      "dense_1: 64\n",
      "dense_2: 32\n",
      "Score: 0.15629726648330688\n",
      "\n",
      "Trial 0034 summary\n",
      "Hyperparameters:\n",
      "channels_1: 12\n",
      "channels_2: 4\n",
      "dense_1: 32\n",
      "dense_2: 16\n",
      "Score: 0.1594385951757431\n",
      "\n",
      "Trial 0026 summary\n",
      "Hyperparameters:\n",
      "channels_1: 8\n",
      "channels_2: 8\n",
      "dense_1: 32\n",
      "dense_2: 16\n",
      "Score: 0.1783667355775833\n",
      "\n",
      "Trial 0059 summary\n",
      "Hyperparameters:\n",
      "channels_1: 16\n",
      "channels_2: 8\n",
      "dense_1: 32\n",
      "dense_2: 32\n",
      "Score: 0.18805596232414246\n",
      "\n",
      "Trial 0005 summary\n",
      "Hyperparameters:\n",
      "channels_1: 4\n",
      "channels_2: 4\n",
      "dense_1: 48\n",
      "dense_2: 32\n",
      "Score: 0.18922336399555206\n",
      "\n",
      "Trial 0037 summary\n",
      "Hyperparameters:\n",
      "channels_1: 12\n",
      "channels_2: 4\n",
      "dense_1: 48\n",
      "dense_2: 32\n",
      "Score: 0.1914486289024353\n",
      "\n",
      "Trial 0062 summary\n",
      "Hyperparameters:\n",
      "channels_1: 16\n",
      "channels_2: 8\n",
      "dense_1: 64\n",
      "dense_2: 16\n",
      "Score: 0.19189421832561493\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9444\n",
      "0 [0.22953803837299347, 0.9444444179534912]\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8889\n",
      "1 [0.3949936628341675, 0.8888888955116272]\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9259\n",
      "2 [0.2761191129684448, 0.9259259104728699]\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.9074\n",
      "3 [0.30827346444129944, 0.9074074029922485]\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8148\n",
      "4 [0.45683610439300537, 0.8148148059844971]\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8519\n",
      "5 [0.3807206451892853, 0.8518518805503845]\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8889\n",
      "6 [0.3948839604854584, 0.8888888955116272]\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8889\n",
      "7 [0.3823985457420349, 0.8888888955116272]\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.9259\n",
      "8 [0.3885621726512909, 0.9259259104728699]\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8704\n",
      "9 [0.43968063592910767, 0.8703703880310059]\n"
     ]
    }
   ],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "best_models = tuner.get_best_models(num_models=10)\n",
    "\n",
    "for i, model in enumerate(best_models):\n",
    "    print(i, model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(10)[0]\n",
    "best_model.save('best_cmodel_no_DA.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22953803837299347, 0.9444444179534912]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
