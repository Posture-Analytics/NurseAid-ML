{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Reading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/training_data_arg.npz', allow_pickle=True)\n",
    "\n",
    "train_set = data['train_set']\n",
    "test_set = data['test_set']\n",
    "val_set = data['val_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(set):\n",
    "    df_ = pd.DataFrame([], columns=['x', 'y'])\t\n",
    "    for i in range(len(set)):\n",
    "        df_ = pd.concat([df_, pd.DataFrame(\n",
    "            {'reading': [set[i]['x'].reshape(24, 32)],\n",
    "            'posture': set[i]['y']}\n",
    "        )])\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1620, 4) (54, 4) (405, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train = create_dataframe(train_set)\n",
    "df_test = create_dataframe(test_set)\n",
    "df_val = create_dataframe(val_set)\n",
    "\n",
    "print(df_train.shape, df_test.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['reading']\n",
    "y_train = df_train['posture']\n",
    "X_val = df_val['reading']\n",
    "y_val = df_val['posture']\n",
    "X_test = df_test['reading']\n",
    "y_test = df_test['posture']\n",
    "# One-hot encode the labels\n",
    "y_train = pd.get_dummies(y_train).values\n",
    "y_val = pd.get_dummies(y_val).values\n",
    "y_test = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[24.77, 25.37, 25.45, 26.17, 26.53, 29.51, 30...\n",
       "0    [[25.74, 26.52, 27.07, 28.7, 30.48, 32.82, 32....\n",
       "0    [[26.5, 27.57, 28.01, 29.04, 30.02, 33.2, 33.1...\n",
       "0    [[25.21, 25.82, 25.93, 26.43, 27.04, 28.96, 29...\n",
       "0    [[25.85, 26.64, 27.07, 28.09, 28.72, 31.57, 32...\n",
       "                           ...                        \n",
       "0    [[24.078905745999865, 23.54478085637246, 24.05...\n",
       "0    [[24.287305549063102, 24.46721305051553, 24.36...\n",
       "0    [[23.187623444806476, 23.419400611664578, 23.4...\n",
       "0    [[24.389370902565755, 24.016248933303498, 24.0...\n",
       "0    [[24.309337096494875, 24.68560284513844, 24.62...\n",
       "Name: reading, Length: 1620, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(x) for x in X_train])\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_val = np.array([np.array(x) for x in X_val])\n",
    "X_val = np.expand_dims(X_val, -1)\n",
    "X_test = np.array([np.array(x) for x in X_test])\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = np.array([np.array(x) for x in y_train])\n",
    "y_test = np.array([np.array(x) for x in y_test])\n",
    "y_val = np.array([np.array(x) for x in y_val])\n",
    "# Convert the data to tensors\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Definition\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_channels_1 = hp.Int('channels_1', min_value=4, max_value=16, step=4)\n",
    "    hp_channels_2 = hp.Int('channels_2', min_value=4, max_value=8, step=4)\n",
    "    hp_dense_1 = hp.Int('dense_1', min_value=16, max_value=64, step=16)\n",
    "    hp_dense_2 = hp.Int('dense_2', min_value=16, max_value=32, step=16)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Conv2D(hp_channels_1, kernel_size=(3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(hp_channels_2, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),  # Flatten the output of the CNN\n",
    "            layers.Dense(hp_dense_1, activation='relu'),\n",
    "            layers.Dense(hp_dense_2, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=500,\n",
    "    max_retries_per_trial=2,\n",
    "    factor=3,\n",
    "    directory='hyperband-laguardia-da',\n",
    "    project_name='posture',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.43209877610206604\n",
      "\n",
      "Best val_accuracy So Far: 0.5259259343147278\n",
      "Total elapsed time: 00h 00m 56s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperband-laguardia-da/posture\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0006 summary\n",
      "Hyperparameters:\n",
      "channels_1: 4\n",
      "channels_2: 8\n",
      "dense_1: 48\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.5259259343147278\n",
      "\n",
      "Trial 0039 summary\n",
      "Hyperparameters:\n",
      "channels_1: 8\n",
      "channels_2: 4\n",
      "dense_1: 64\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.5135802626609802\n",
      "\n",
      "Trial 0013 summary\n",
      "Hyperparameters:\n",
      "channels_1: 12\n",
      "channels_2: 4\n",
      "dense_1: 32\n",
      "dense_2: 32\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.4938271641731262\n",
      "\n",
      "Trial 0002 summary\n",
      "Hyperparameters:\n",
      "channels_1: 16\n",
      "channels_2: 8\n",
      "dense_1: 48\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.4790123403072357\n",
      "\n",
      "Trial 0003 summary\n",
      "Hyperparameters:\n",
      "channels_1: 4\n",
      "channels_2: 4\n",
      "dense_1: 64\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.47654321789741516\n",
      "\n",
      "Trial 0014 summary\n",
      "Hyperparameters:\n",
      "channels_1: 16\n",
      "channels_2: 4\n",
      "dense_1: 64\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.47654321789741516\n",
      "\n",
      "Trial 0042 summary\n",
      "Hyperparameters:\n",
      "channels_1: 8\n",
      "channels_2: 8\n",
      "dense_1: 48\n",
      "dense_2: 32\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.47654321789741516\n",
      "\n",
      "Trial 0050 summary\n",
      "Hyperparameters:\n",
      "channels_1: 4\n",
      "channels_2: 4\n",
      "dense_1: 48\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.47160494327545166\n",
      "\n",
      "Trial 0019 summary\n",
      "Hyperparameters:\n",
      "channels_1: 12\n",
      "channels_2: 4\n",
      "dense_1: 64\n",
      "dense_2: 16\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.46666666865348816\n",
      "\n",
      "Trial 0051 summary\n",
      "Hyperparameters:\n",
      "channels_1: 4\n",
      "channels_2: 8\n",
      "dense_1: 32\n",
      "dense_2: 32\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.46666666865348816\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_model.save('best_model_hyperband.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0575 - accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0575002431869507, 0.5555555820465088]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
